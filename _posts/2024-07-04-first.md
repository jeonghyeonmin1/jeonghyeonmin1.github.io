---
layout: posts
title: "1주차"
---

# 논문 리뷰

---

## 계획
Challenge1) SAR segmentation (7.18 발표)

Goal : (precision:90 recall:80 || F1score:87) &&  연산량 GFlops=0.5  (FLOPS = 속도(GPU), FLOPs = 양(모델))
- 연산량 낮을수록 좋은거

논문 리뷰 1/2~3days(2Q per 1 + 아이디어 도출)

오마카세 : 1/2week 화(7pm) - start(7.2)

논문리뷰 : 매주 월/수(2pm)(발표날에는 생략) + 이때 질문하면서 논문 쓸 주제 생각해보기(~7.31)

---

## 결과

### \<MobileNetV1\>
너비,깊이 나눠서 연산

- depth-wise convolution (공간 방향으로 연산)

![사진](/assets/image/2024-07-04-first-0.png){: width="60%" height="60%" .align-center}

- Point-wise Convolution(공간 X, 채널 방향으로 연산)

![사진](/assets/image/2024-07-04-first-1.png){: width="60%" height="60%" .align-center}

- depth-wise Convolution + point-wise Convolution

![사진](/assets/image/2024-07-04-first-2.png){: width="60%" height="60%" .align-center}


### \<mobileNetV2\>
병목현상 :  정보가 몰릴 때 중요한 정보만 통과시키는 것을 뜻함.
<br><br>

기존 병목현상 동작 방식
: 128 → 32(중요한 정보로 압축) → 128(확장시켜 중요한 정보들로만 채움) → 불필요한 정보를 없애서 중요한 정보를 더 잘 볼 수 있게 해줌
<br><br>

\<inverted bottleneck\>

배경 : 기존 bottleneck 은 Relu로 인해 중요한 정보가 소실되는 문제가 있음

그래서 반대로 확장시켜 Relu를 사용해도 중요한 정보 손실이 나지 않고 non-linearity를 유지할 수 있게할 방법을 생각하게 됨 → "Inverted bottleneck"

동작 방식 : 128 → 512 → 256 → 128(128~256) 이런 식으로 기존의 bottleneck과 달리 모든 정보를 거의 다 볼 수 있어 정보 손실이 줄어듦

문제점 : 연산량이 많아진다는 단점이 존재 → mobileNetV1 에서 사용된 Depth-wise Separable Convolution(Depth-wise + point-wise)을 통해 연산량을 줄여줌 

### \<MobileNetV3\>

NAS(Neural Architecture Search) : 신경망의 구조를 자동으로 설계하는 기술로, 최적의 신경망 아키텍처를 찾기 위해 기계 학습 기법을 사용

swish : 음수 값이여도 갱생의 기회를 줌

![사진](/assets/image/2024-07-04-first-3.png){: width="60%" height="60%" .align-center}

![사진](/assets/image/2024-07-04-first-4.png){: width="60%" height="60%" .align-center}

hswish: swish 에서 e^x 계산이 복잡해져서 보완하기 위해 나옴

![사진](/assets/image/2024-07-04-first-5.png){: width="60%" height="60%" .align-center}

MobileNetV3 정리 ⇒ NAS 를 통해 모델 구조를 뽑아내고 hard-swish를 적용시켜 성능을 향상시킨 모델
